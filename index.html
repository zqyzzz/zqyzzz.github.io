<!DYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Qinye Zhou</title>
  
  <meta name="author" content="Qinye Zhou">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name> Qinye Zhou </name>
              </p>
              <p>I am a master student working on multimodal machine learning at <a href="https://mediabrain.sjtu.edu.cn/">Shanghai Jiao Tong University</a>.
		     </p>
		    <p>
			    I received my bachelor degree from <a href='https://www.sjtu.edu.cn/'> Shanghai Jiao Tong University (SJTU)</a> in June 2021. 
              </p>
	      <p>
		      My current research interest is in open-world representation learning and AIGC.
              </p>      
		    
              <p style="text-align:center">
                <a href="mailto:zhouqinye@sjtu.edu.cn">Email</a> &nbsp/&nbsp
                <a href="https://github.com/zqyzzz">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:18%;max-width:18%">
              <a href="zqy.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="zqy.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
	</tbody></table>
	<br />
		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading><b></bold>Research</b></heading>

	  <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="grounded.png" width="320" height="100" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://lipurple.github.io/Grounded_Diffusion/">
                <papertitle>Open-vocabulary Object Segmentation with Diffusion Models</papertitle>
              </a>
              <br>
              <a>Ziyi Li* </a>,
              <strong>Qinye Zhou* </strong>,
              <a href="https://cmic.sjtu.edu.cn/CN/show.aspx?info_lb=35&info_id=1341&flag=35">Xiaoyun Zhang </a>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang </a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang </a>,
              <a href="https://weidixie.github.io/">Weidi Xie </a>
              <br>
		    <em> International Conference on Computer Vision (ICCV)</em>, 2023
              <!-- <em>arXiv</em>, 2023 (under review) -->
              <p>we propose to augment a pre-trained text-to-image diffusion model with the ability of open-vocabulary objects grounding, i.e., simultaneously generating images and segmentation masks for the corresponding visual entities described in the text prompt.
              </p>
          </td>
	 </tr> 

	  <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:40%;vertical-align:middle">
              <img src="ARIS.png" width="320" height="160" style="border-style: none">
            </td>
            <td style="padding:10px;width:60%;vertical-align:middle">
              <a href="https://lipurple.github.io/ARIS_Webpage//">
                <papertitle>A Simple Plugin for Transforming Images to Arbitrary Scales</papertitle>
              </a>
              <br>
              <strong>Qinye Zhou* </strong>,
              <a>Ziyi Li* </a>,
              <a href="https://weidixie.github.io/">Weidi Xie </a>,
              <a href="https://cmic.sjtu.edu.cn/CN/show.aspx?info_lb=35&info_id=1341&flag=35">Xiaoyun Zhang </a>,
	      <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang </a>,
	      <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>
              <br>
			<em> British Machine Vision Conference (BMVC)</em>, 2022
              <p>we propose to develop a general <strong>plugin</strong> that can be inserted into existing super-resolution models, conveniently augmenting their ability towards <strong>A</strong>rbitrary <strong>R</strong>esolution <strong>I</strong>mage <strong>S</strong>caling, thus termed <strong>ARIS</strong>.</p>
            </td>
	 </tr> 

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
		Based on a template by <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
<!--for page update--> 
